---
title       : Coursera - Capstone Project
subtitle    : Text Prediction
author      : VN
job         : 
framework   : io2012        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}
hitheme     : tomorrow      # 
widgets     : []            # {mathjax, quiz, bootstrap}
mode        : selfcontained # {standalone, draft}
knit        : slidify::knit2slides
---
<style>
.ninety {
   font-size: 90%;
}
</style>


# Overview

This presentation has been prepared as part of the Capstone project submission of Coursera Data Science. The assignment was to build a prediction algorithm and create a product which leverages the same to predict the next word.    

The assignment consists of the below two deliverables :     

- (A) Shiny App which takes text as input and predicts the next word    
- (B) Presentation of 5 slides (using R Studio Presenter) covering algorithm and how to use the app          
This presentation addresses deliverable (B).      

Model has been prepared from 10% of the sample data set provided (SwiftKey) across blog, news and twitter feeds    


--- .class #id 


**Model**   
- Ngram (uni, bi & tri) built using R packages which provides -  tokens  &  frequency        
- Prepare model from NGram with the following :  
     -  context (token without last word - to be matched with the input text in prediction)    
     -  word (last word of the token - would be returned as predicted word)    
     -  ngram (1/2/3 to indicate uni, bi or tri gram)    
     -  probability (frequency for word & context / frequency for context)     
     
**Algorithm**    
- Pre-process input string using same steps as in model preparation    
- Match starting with NGram = 3 and go down to 1. Limit to 3 entries with highest probability        
    - NGram = 3 : last two words from input text ==  context, sort by probability    
    - NGram = 2 : last  word from input text == context, sort by probability    
    - NGram = 1 : pick top 3 words (context is NULL), sorted by probability        
- Return the list of word matched by above logic. Maximum of 3 entries would only be shown   

--- .class #id 

# Shiny App    
The shiny app UI and usage detailed below :     
![](ShinyAppImg.png)

ShinyApp available at <https://vnet.shinyapps.io/predictnxtword/>    


--- .class #id 

# Points noted  

- RWeka tokeniser - out of memory Java heapsize issue. Generating uni, bi and tri ngrams seperately and merging them to prepare final model    
- Model generation was done using RWeka, TDM and ngram. Considerable improvement in performance was observed by moving to the final model using ngram.     
- Other optimization suggested for performance improvement around using list, data frame, sapply etc were also implemented    

For details lookup the versions of the NGram function included in git        



# References       

- SwiftKey data set shared as part of the course receivables    
- Script repository <https://github.com/vinodneth/CStone>     
- Shiny App available at <https://vnet.shinyapps.io/predictnxtword/>    

